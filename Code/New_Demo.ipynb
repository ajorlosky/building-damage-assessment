{"cells":[{"cell_type":"markdown","source":["# Interactive Demo for User to perform Building Classification"],"metadata":{"id":"X3P-Ks5blqte"}},{"cell_type":"markdown","source":["This demo represents a potential product for a user of our application to be able to classify damage of all buildings in a satellite image using any one of our methods CNN, Edge Detection CNN, Siamese Neural Network, SVM, or KNN. We have the best performance with KNN, but all of them are promising for different use cases.\n"],"metadata":{"id":"G-e264kUMhQL"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":384},"executionInfo":{"elapsed":9483,"status":"error","timestamp":1716394206057,"user":{"displayName":"Stavros Mitrolaris","userId":"09956768889287638782"},"user_tz":240},"id":"n8i-gSo_NeI2","outputId":"80f786c3-f639-4c61-daa0-06bb54384aaf"},"outputs":[{"output_type":"error","ename":"MessageError","evalue":"Error: credential propagation was unsuccessful","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-adf7c59f5c99>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Mount Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# TensorFlow and tf.keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    131\u001b[0m   )\n\u001b[1;32m    132\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"]}],"source":["### Install required packages and Mount Drive\n","\n","# Mount Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# TensorFlow and tf.keras\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n","\n","# Commonly used modules\n","import numpy as np\n","import os\n","import sys\n","import json\n","import math\n","\n","# Images, plots, display, and visualization\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import seaborn as sns\n","import cv2\n","import IPython\n","from six.moves import urllib\n","from google.colab.patches import cv2_imshow as show\n","import random\n","from collections import Counter\n","\n","\n","# sci-kit learn\n","from sklearn.decomposition import PCA\n","from sklearn import svm\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import f1_score\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import f1_score, accuracy_score\n","\n","\n","#siamese imports\n","from keras.layers import Input, Dense, InputLayer, Conv2D, MaxPooling2D, UpSampling2D, InputLayer, Concatenate, Flatten, Reshape, Lambda, Embedding, dot, GlobalAveragePooling2D\n","from keras.models import Model, load_model, Sequential\n","import tensorflow.keras.backend as K\n","from keras import metrics\n","from keras.optimizers import SGD\n","from sklearn.utils import compute_class_weight\n","\n","print(tf.__version__)\n","\n","class Demo:\n","\n","    def __init__(self):\n","        self.NAME = None\n","        self.disaster = None\n","        self.model = None\n","\n","    ### User Interfacing Functions:\n","\n","    # Get user name for path specification\n","    def get_user_name(self):\n","        valid_usernames = [\"ALAN\", \"PAT\", \"ANDY\"]\n","\n","        while True:\n","            # Asking the user to input their name\n","            user_name = input(\"Please enter your name: \").strip().upper()\n","\n","            # Checking if the entered username is valid\n","            if user_name in valid_usernames:\n","                # Greeting the user\n","                print(f\"Hello, {user_name}! Nice to meet you.\")\n","                # Returning the user's name\n","                self.NAME = user_name\n","                break  # Exit the loop since a valid username is entered\n","            else:\n","                print(\"Invalid username. Please enter ALAN, PAT, or ANDY.\")\n","\n","    # Choose specific disaster\n","    def choose_disaster(self):\n","        print(\"Disasters:\\n\")\n","        print(\"1. guatemala-volcano\")\n","        print(\"2. hurricane-florence\")\n","        print(\"3. hurricane-harvey\")\n","        print(\"4. hurricane-michael\")\n","        print(\"5. hurricane-matthew\")\n","        print(\"6. socal-fire\")\n","        print(\"7. santa-rosa-wildfire\")\n","        print(\"8. midwest-flooding\")\n","        print(\"9. palu-tsunami\")\n","        print(\"10. mexico-earthquake\\n\")\n","\n","        num = int(input(\"Enter a number to specify the disaster: \"))\n","        while(num < 1 or num > 10):\n","          num = int(input(\"\\nInput was not valid. Enter a number to specify the disaster: \"))\n","\n","        print(\"\\n\\n\")\n","\n","        match num:\n","          case 1: disaster = 'guatemala-volcano'\n","          case 2: disaster = 'hurricane-florence'\n","          case 3: disaster = 'hurricane-harvey'\n","          case 4: disaster = 'hurricane-michael'\n","          case 5: disaster = 'hurricane-matthew'\n","          case 6: disaster = 'socal-fire'\n","          case 7: disaster = 'santa-rosa-wildfire'\n","          case 8: disaster = 'midwest-flooding'\n","          case 9: disaster = 'palu-tsunami'\n","          case 10: disaster = 'mexico-earthquake'\n","\n","        self.disaster = disaster\n","        return disaster\n","\n","    # Choose model\n","    def choose_model(self):\n","        print(\"Models:\\n\")\n","        print(\"1. CNN\")\n","        print(\"2. CNN with Edge Detection\")\n","        print(\"3. Siamese NN\")\n","        print(\"4. SVM\")\n","        print(\"5. KNN Classifier\")\n","\n","        num = int(input(\"Enter a number to specify the model: \"))\n","        while(num < 1 or num > 5):\n","          num = int(input(\"\\nInput was not valid. Enter a number to specify the model: \"))\n","\n","        print(\"\\n\\n\")\n","\n","        self.model = num\n","\n","        return num\n","\n","    ### Preprocessing Functions:\n","\n","    # given json data for a building, this function parses the json data and\n","    # returns an array of points that outline the polygon mask of the building\n","\n","    def get_points(self, json_building):\n","        #split the string\n","        spaces = json_building['wkt'].split(' ')\n","\n","        # print(spaces)\n","\n","        #remove the first element 'POLYGON'\n","        spaces.pop(0)\n","\n","        #remove the parenthesis from the first element\n","        spaces[0] = spaces[0][2::]\n","\n","        #remove the parethesis of the last element\n","        spaces[len(spaces)-1] = spaces[len(spaces)-1][:-2]\n","\n","        #get rid of the commas in the second point\n","        for i in range(len(spaces)):\n","          spaces[i] = spaces[i].replace(\",\",\"\")\n","\n","        # print(spaces)\n","\n","        #make them integers and tuples for points\n","        points = []\n","        for i in range(0,len(spaces),2):\n","          points.append((int(float(spaces[i])), int(float(spaces[i+1]))))\n","\n","        points = np.array(points)\n","\n","        return points\n","\n","    # given an array of images and a size, this function adds black to the borders\n","    # of the images to make all the images have the dimensions (size x size x 3)\n","    def make_same_dimensions(self, images, size):\n","\n","        square_dim = size\n","\n","        # print(\"square_dim: \" + str(square_dim))\n","\n","        new_images = []\n","        img_count = 1\n","\n","        # make all images have same dimensions\n","        for img in images:\n","\n","          # print(\"\\nimage \" + str(img_count))\n","          img_count+=1\n","          #print(str(img_count) + \": \" + str(img.shape))\n","\n","          # print(\"curr_rows : \" + str(curr_rows))\n","          # print(\"curr_cols: \" + str(curr_cols))\n","\n","          new_img = img\n","          curr_rows , curr_cols, _ = new_img.shape\n","\n","\n","          if curr_rows > square_dim:        #dsize is (width,height) which is -> (cols,rows)\n","            new_img = cv2.resize(new_img, dsize=(curr_cols,square_dim), interpolation=cv2.INTER_CUBIC)\n","            curr_rows , curr_cols, _ = new_img.shape\n","            #print(img_count, \"here\")\n","\n","          if curr_cols > square_dim:\n","            new_img = cv2.resize(new_img, dsize=(square_dim,curr_rows), interpolation=cv2.INTER_CUBIC)\n","            curr_rows , curr_cols, _ = new_img.shape\n","\n","\n","          curr_rows , curr_cols, _ = new_img.shape\n","          # add to cols of image if needed\n","          if square_dim > curr_cols:\n","            difference = square_dim - curr_cols\n","\n","            # print(\"difference in cols: \" + str(difference))\n","\n","            # creates column array with $rows number of rows\n","            d = np.array([[[0, 0, 0]] for x in range(curr_rows)])\n","            # print(d.shape)\n","\n","            # case where you just add one col to the img\n","            if difference == 1:\n","                new_img = np.hstack((new_img, d))\n","            # case where you add equal amount to left and right of image\n","            else:\n","              # add one col to left and right of img\n","              new_img = np.hstack((new_img, d))\n","              new_img = np.hstack((d, new_img))\n","\n","              # add rest of cols to left/right of img\n","              for i in range(math.floor(difference/2)-1):\n","                new_img = np.hstack((new_img, d))\n","                new_img = np.hstack((d, new_img))\n","\n","              # if difference is odd, have an extra column to add\n","              if difference%2 == 1:\n","                new_img = np.hstack((new_img, d))\n","\n","          # update variables to match updated image\n","          curr_rows , curr_cols, _ = new_img.shape\n","\n","          # add to rows of image if needed\n","          if square_dim > curr_rows:\n","            difference = square_dim - curr_rows\n","\n","            # print(\"difference in rows: \" + str(difference))\n","\n","            # creates row array with $height number of cols\n","            d = np.array([[[0, 0, 0] for x in range(curr_cols)]])\n","            # print(d.shape)\n","\n","            # case where you just add one row to the img\n","            if difference == 1:\n","                new_img = np.vstack((new_img, d))\n","            # case where you add equal amount to top and bottom of image\n","            else:\n","              # add one col to left and right of img\n","              new_img = np.vstack((new_img, d))\n","              new_img = np.vstack((d, new_img))\n","\n","              # add rest of cols to left/right of img\n","              for i in range(math.floor(difference/2)-1):\n","                new_img = np.vstack((new_img, d))\n","                new_img = np.vstack((d, new_img))\n","\n","              # if difference is odd, have an extra column to add\n","              if difference%2 == 1:\n","                new_img = np.vstack((new_img, d))\n","\n","          new_rows, new_cols, _ = new_img.shape\n","\n","          if new_rows != 150 or new_cols != 150:\n","            print(\"old dim: \", img.shape)\n","            print(\"new dim:\", new_img.shape)\n","\n","          # print(\"\\nnew_rows: \" + str(new_rows))\n","          # print(\"new_cols: \" + str(new_cols))\n","\n","          new_images.append(new_img)\n","\n","        return new_images\n","\n","    def make_same_dimensions_siamese(self,images, size):\n","\n","      # square_dim = max(max_rows , max_cols)\n","      square_dim = size\n","\n","      # print(\"square_dim: \" + str(square_dim))\n","\n","      new_images = []\n","      img_count = 1\n","\n","      # make all images have same dimensions\n","      for pair in images:\n","\n","        # print(\"\\nimage \" + str(img_count))\n","        img_count+=1\n","\n","        new_img0 = pair[0]\n","        new_img1 = pair[1]\n","        curr_rows , curr_cols, _ = new_img0.shape\n","\n","\n","        if curr_rows > square_dim:        #dsize is (width,height) which is -> (cols,rows)\n","          new_img0 = cv2.resize(new_img0, dsize=(curr_cols,square_dim), interpolation=cv2.INTER_CUBIC)\n","          curr_rows , curr_cols, _ = new_img0.shape\n","\n","          #do the same thing to newimg1\n","          new_img1 = cv2.resize(new_img1, dsize=(curr_cols,square_dim), interpolation=cv2.INTER_CUBIC)\n","\n","        if curr_cols > square_dim:\n","          new_img0 = cv2.resize(new_img0, dsize=(square_dim,curr_rows), interpolation=cv2.INTER_CUBIC)\n","          curr_rows , curr_cols, _ = new_img0.shape\n","\n","          new_img1 = cv2.resize(new_img1, dsize=(square_dim,curr_rows), interpolation=cv2.INTER_CUBIC)\n","\n","        curr_rows , curr_cols, _ = new_img0.shape\n","        # add to cols of image if needed\n","        if square_dim > curr_cols:\n","          difference = square_dim - curr_cols\n","\n","          # print(\"difference in cols: \" + str(difference))\n","\n","          # creates column array with $rows number of rows\n","          d = np.array([[[0, 0, 0]] for x in range(curr_rows)])\n","          # print(d.shape)\n","\n","          # case where you just add one col to the img\n","          if difference == 1:\n","              new_img0 = np.hstack((new_img0, d))\n","              new_img1 = np.hstack((new_img1, d))\n","          # case where you add equal amount to left and right of image\n","          else:\n","            # add one col to left and right of img\n","            new_img0 = np.hstack((new_img0, d))\n","            new_img0 = np.hstack((d, new_img0))\n","\n","            new_img1 = np.hstack((new_img1, d))\n","            new_img1 = np.hstack((d, new_img1))\n","\n","            # add rest of cols to left/right of img\n","            for i in range(math.floor(difference/2)-1):\n","              new_img0 = np.hstack((new_img0, d))\n","              new_img0 = np.hstack((d, new_img0))\n","\n","              new_img1 = np.hstack((new_img1, d))\n","              new_img1 = np.hstack((d, new_img1))\n","\n","\n","            # if difference is odd, have an extra column to add\n","            if difference%2 == 1:\n","              new_img0 = np.hstack((new_img0, d))\n","              new_img1 = np.hstack((new_img1, d))\n","\n","\n","        # update variables to match updated image\n","        curr_rows , curr_cols, _ = new_img0.shape\n","\n","        # add to rows of image if needed\n","        if square_dim > curr_rows:\n","          difference = square_dim - curr_rows\n","\n","          # print(\"difference in rows: \" + str(difference))\n","\n","          # creates row array with $height number of cols\n","          d = np.array([[[0, 0, 0] for x in range(curr_cols)]])\n","          # print(d.shape)\n","\n","          # case where you just add one row to the img\n","          if difference == 1:\n","              new_img0 = np.vstack((new_img0, d))\n","              new_img1 = np.vstack((new_img1, d))\n","          # case where you add equal amount to top and bottom of image\n","          else:\n","            # add one col to left and right of img\n","            new_img0 = np.vstack((new_img0, d))\n","            new_img0 = np.vstack((d, new_img0))\n","\n","            new_img1 = np.vstack((new_img1, d))\n","            new_img1 = np.vstack((d, new_img1))\n","\n","            # add rest of cols to left/right of img\n","            for i in range(math.floor(difference/2)-1):\n","              new_img0 = np.vstack((new_img0, d))\n","              new_img0 = np.vstack((d, new_img0))\n","\n","              new_img1 = np.vstack((new_img1, d))\n","              new_img1 = np.vstack((d, new_img1))\n","\n","\n","            # if difference is odd, have an extra column to add\n","            if difference%2 == 1:\n","              new_img0 = np.vstack((new_img0, d))\n","              new_img1 = np.vstack((new_img1, d))\n","\n","        new_rows, new_cols, _ = new_img0.shape\n","\n","        #if new_rows != 150 or new_cols != 150:\n","          #print(\"old dim: \", img[0].shape)\n","          #print(\"new dim:\", new_img0.shape)\n","\n","        # print(\"\\nnew_rows: \" + str(new_rows))\n","        # print(\"new_cols: \" + str(new_cols))\n","\n","        new_images.append([new_img0,new_img1])\n","\n","      return new_images\n","\n","    # given the json data of a building and the image the building is from, this\n","    # function creates a cropped image of just the building from the entire image\n","    def crop_image(self, building, img):\n","\n","        points = self.get_points(building)\n","        # print(points)\n","        sum_x = 0\n","        sum_y = 0\n","        for x,y in points:\n","          sum_x += x\n","          sum_y += y\n","\n","        center_x = round(sum_x/len(points))\n","        center_y = round(sum_y/len(points))\n","        # print(center_x)\n","        # print(center_y)\n","        # image[ miny:maxy, minx:maxx]\n","        # show(img_post[center_y-50:center_y+50, center_x-50:center_x+50])\n","\n","        # source for below code: https://stackoverflow.com/questions/48301186/cropping-concave-polygon-from-image-using-opencv-python\n","\n","        rect = cv2.boundingRect(points)\n","        x,y,w,h = rect\n","\n","        croped = img[y:y+h, x:x+w].copy()\n","\n","        ## (2) make mask\n","        pts = points - points.min(axis=0)\n","\n","        mask = np.zeros(croped.shape[:2], np.uint8)\n","        cv2.drawContours(mask, [pts], -1, (255, 255, 255), -1, cv2.LINE_AA)\n","\n","        ## (3) do bit-op\n","        dst = cv2.bitwise_and(croped, croped, mask=mask)\n","\n","        return dst\n","\n","    # Using json path from username, gather the images from the disaster\n","    def gather_images_json(self, disaster):\n","\n","        # Identify user and pull base directory path\n","        if self.NAME == \"PAT\":\n","            base_dir = '/content/drive/MyDrive/Capstone Project/Dataset1/train/images/'\n","        elif self.NAME == \"ALAN\":\n","            base_dir = \"/content/drive/MyDrive/SeniorSpring/ENEE439D/Capstone Project/Dataset1/train/images/\"\n","        elif self.NAME == \"ANDY\":\n","            base_dir = '/content/drive/MyDrive/Spring 2024/ENEE 439D/Capstone Project/Dataset1/train/images/'\n","        else:\n","            raise Exception(\"Invalid user\")\n","\n","        # Specify disaster name, so training and testing based on disaster subset\n","        # Select from: guatemala-volcano (16 images), hurricane-florence, hurricane-harvey,\n","        #              hurricane-michael, hurricane-matthew, socal-fire, santa-rosa-wildfire,\n","        #              midwest-flooding, palu-tsunami, or mexico-earthquake\n","        disaster_name = disaster\n","\n","        count_images = 5\n","\n","        images_train = []\n","        json_images_train = []\n","\n","        i = 1\n","        while len(images_train) < count_images:\n","            file_name = f\"{disaster_name}_{i:08d}_post_disaster.png\"\n","            img_path = os.path.join(base_dir, file_name)\n","            label_path = img_path.replace('png', 'json').replace('images', 'labels')\n","\n","            # If files exist for both image and label, then add it as a train or test image/label\n","            if os.path.exists(img_path) and os.path.exists(label_path):\n","                images_train.append(img_path)\n","                with open(label_path, \"rb\") as file:\n","                    data = json.load(file)\n","                    json_images_train.append(data)\n","\n","            i += 1\n","\n","        return images_train, json_images_train\n","\n","      #for gathering the images for the siamese modeling\n","    def gather_images_siamese_json(self,disaster):\n","\n","      if self.NAME == \"PAT\":\n","        base_dir = '/content/drive/MyDrive/Capstone Project/Dataset1/train/images/'\n","      elif self.NAME == \"ALAN\":\n","        base_dir = \"/content/drive/MyDrive/SeniorSpring/ENEE439D/Capstone Project/Dataset1/train/images/\"\n","      elif self.NAME == \"ANDY\":\n","        base_dir = '/content/drive/MyDrive/Spring 2024/ENEE 439D/Capstone Project/Dataset1/train/images/'\n","      else:\n","        raise Exception(\"Invalid user\")\n","\n","      disaster_name = disaster\n","\n","      curr_count_train = 0\n","      curr_count_test = 0\n","      count_train = 11\n","      count_test = 4\n","      images_train = []\n","      json_images_train = []\n","\n","      images_test = []\n","      json_images_test = []\n","      train = True\n","\n","      for file in os.listdir(base_dir):\n","        if disaster_name in file and file.endswith(\"post_disaster.png\"):\n","          if train:\n","            curr_count_train+=1\n","          else:\n","            curr_count_test+=1\n","\n","          #make the pre and post images a pair:\n","          img_path = base_dir+file\n","          pre_img_path = base_dir+file.replace('post_disaster.png',\"pre_disaster.png\")\n","          post_img_path = base_dir+file\n","          pre_post_pair = [pre_img_path,post_img_path]\n","\n","          if train:\n","            images_train.append(pre_post_pair)\n","          else:\n","            images_test.append(pre_post_pair)\n","\n","\n","          # get the json data\n","          label_path = img_path.replace('png', 'json').replace('images', 'labels')\n","          with open(label_path, \"rb\") as file:\n","              data = json.load(file)\n","          if train:\n","            json_images_train.append(data)\n","          else:\n","            json_images_test.append(data)\n","\n","          if curr_count_train >= count_train:\n","            train = False\n","\n","          if not train and curr_count_test >= count_test:\n","            break\n","\n","      return images_train,images_test,json_images_train,json_images_test\n","\n","\n","\n","\n","\n","    #Used as a reference for function idea: https://www.kaggle.com/code/lezwon/xview2-challenge#kln-47, but chose a different but similar method\n","    #referene for cv2.fillpoly: https://www.geeksforgeeks.org/draw-a-filled-polygon-using-the-opencv-function-fillpoly/\n","\n","    # function used to draw labels and output the image with our own dimensions**\n","    def draw_labels(self, img, data):\n","      for building in data['features']['xy']:\n","\n","        #split the string\n","        spaces = building['wkt'].split(' ')\n","\n","        #remove the first element 'POLYGON'\n","        spaces.pop(0)\n","        #remove the parenthesis from the first element\n","        spaces[0] = spaces[0][2::]\n","        #remove the parethesis of the last element\n","        spaces[len(spaces)-1] = spaces[len(spaces)-1][:-2]\n","\n","        #get rid of the commas in the second point\n","        for i in range(len(spaces)):\n","          spaces[i] = spaces[i].replace(\",\",\"\")\n","\n","        #make them integers and tuples for points\n","        points = []\n","        for i in range(0,len(spaces),2):\n","          points.append((int(float(spaces[i])), int(float(spaces[i+1]))))\n","\n","        points = np.array(points)\n","\n","        #grab the damage label\n","        damage_label = building[\"properties\"][\"subtype\"]\n","\n","        #CV2 uses BGR not RGB\n","        #default to cyan\n","        COLOR = (255,255,25)\n","        if damage_label == \"no-damage\":\n","          #no-damage is white\n","          COLOR = (255,255,255)\n","        if damage_label == \"minor-damage\":\n","          #minor damage is green\n","          COLOR = (128,255,102)\n","        if damage_label == \"major-damage\":\n","          #major is orange\n","          COLOR = (0,153,250)\n","        if damage_label == \"destroyed\":\n","          #red for destoyed\n","          COLOR = (0,0,255)\n","\n","        #draw the proper polygon\n","        cv2.fillPoly(img, [points],COLOR)\n","\n","      return img\n","\n","    # Image cropping to specific width and height\n","    def show_with_size(self, image, width, height, title):\n","        plt.figure(figsize=(width, height))\n","        plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n","        plt.title(title)\n","        plt.axis('off')\n","        plt.show()\n","\n","    # Show pre and post disaster images\n","    def show_pre_post(self, images_train, index):\n","        sample_img = images_train[index]\n","\n","        # Show pre-disaster image\n","        img_path_pre = sample_img.replace('post', 'pre')\n","        img_pre = cv2.imread(img_path_pre)\n","        # print(\"Pre disaster Building Damage Assessment Image: \")\n","        # self.show_with_size(img_pre, width=8, height=6, \"Predisaster Image\")  # Adjust width and height as needed\n","\n","        # Show post-disaster image\n","        img_path_post = img_path_pre.replace('pre', 'post')\n","        img_post = cv2.imread(img_path_post)\n","        # print(\"Post disaster Building Damage Assessment Image: \")\n","        # self.show_with_size(img_post, width=8, height=6, \"Postdisaster Image\")  # Adjust width and height as needed\n","\n","        fig = plt.figure(figsize=(12, 12))\n","        ax1 = fig.add_subplot(2,2,1)\n","        ax1.imshow(img_pre)\n","        ax1.title.set_text('Pre disaster')\n","\n","        ax2 = fig.add_subplot(2,2,2)\n","        ax2.imshow(img_post)\n","        ax2.title.set_text('Post disaster')\n","\n","     # Draw Labels Onto Image\n","    def show_post_labels(self, images_train, index):\n","        sample_img = images_train[index]\n","        img_post = cv2.imread(sample_img)\n","\n","        # get the json data\n","        label_path = sample_img.replace('png', 'json').replace('images', 'labels')\n","        # takes a while for below code to run so once it runs, work with data variable in new cell\n","        with open(label_path, \"rb\") as file:\n","            data = json.load(file)\n","\n","        img_true_labels = self.draw_labels(img_post,data)\n","        self.show_with_size(img_true_labels,6,8, \"Ground Truth Postdisaster Image\")\n","\n","    # create train and test data without even damage level split\n","    def get_train_test_split(self, images_train, json_images_train):\n","\n","        # Splitting images based on the provided ratio\n","        train_images = []\n","        train_labels = []\n","        test_images = []\n","        test_labels = []\n","\n","        ratio = 0.85\n","\n","        for i in range(len(images_train)):\n","\n","            img_path = images_train[i]\n","            data = json_images_train[i]\n","\n","            img = cv2.imread(img_path)\n","\n","            for building in data['features']['xy']:\n","                damage_label = building[\"properties\"][\"subtype\"]\n","                if damage_label != \"un-classified\":\n","                    cropped_img = self.crop_image(building, img)\n","\n","                    # Append to train or test based on the split ratio\n","                    if i != 2 and np.random.uniform(0, 1) < ratio:\n","                        train_images.append(cropped_img)\n","                        if damage_label == \"no-damage\":\n","                            train_labels.append(0)\n","                        elif damage_label == \"minor-damage\":\n","                            train_labels.append(1)\n","                        elif damage_label == \"major-damage\":\n","                            train_labels.append(2)\n","                        elif damage_label == \"destroyed\":\n","                            train_labels.append(3)\n","                    else:\n","                        test_images.append(cropped_img)\n","                        if damage_label == \"no-damage\":\n","                            test_labels.append(0)\n","                        elif damage_label == \"minor-damage\":\n","                            test_labels.append(1)\n","                        elif damage_label == \"major-damage\":\n","                            test_labels.append(2)\n","                        elif damage_label == \"destroyed\":\n","                            test_labels.append(3)\n","\n","        # Resize images to the same dimensions\n","        train_images = self.make_same_dimensions(train_images, 150)\n","        test_images = self.make_same_dimensions(test_images, 150)\n","\n","        for i in range(0,len(train_images)):\n","          if train_images[i].shape != (150,150,3):\n","            print(i,train_images[i].shape)\n","\n","        train_images = np.array(train_images)\n","        train_labels = np.array(train_labels)\n","        test_images = np.array(test_images)\n","        test_labels = np.array(test_labels)\n","\n","        return train_images, train_labels, test_images, test_labels\n","\n","    # Count the occurrences of each value\n","    def print_class_stats(self, train_or_test_labels):\n","\n","        # print num images in each class for test images\n","        counts = Counter(train_or_test_labels)\n","\n","        # Define label descriptions\n","        label_descriptions = {\n","            0: \"No damage\",\n","            1: \"Minor Damage\",\n","            2: \"Major Damage\",\n","            3: \"Destroyed\"\n","        }\n","\n","        # Print the counts with descriptions\n","        for value, count in counts.items():\n","            damage = label_descriptions.get(value, \"Unclassified\")\n","            print(f\"{damage}: {count}\")\n","\n","    ### Model Selection, Training, and Testing\n","\n","    ## CNN\n","\n","    # Defines the structure of our CNN. Change this according to our goals\n","    def build_CNN(self):\n","          model = keras.Sequential()\n","\n","          # 128 convolution filters used each of size 3x3\n","          model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', input_shape=(150, 150, 3)))  #was 150,150,3 making 300,300,3\n","\n","          # 64 convolution filters used each of size 3x3\n","          model.add(Conv2D(64, (3, 3), activation='relu'))\n","\n","          # 32 convolution filters used each of size 3x3\n","          model.add(Conv2D(32, (3, 3), activation='relu'))\n","\n","          # choose the best features via pooling\n","          model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","          # randomly turn neurons on and off to improve convergence\n","          model.add(Dropout(0.25))\n","\n","          # flatten since too many dimensions, we only want a classification output\n","          model.add(Flatten())\n","\n","          # fully connected to get all relevant data\n","          model.add(Dense(128, activation='relu'))\n","\n","          # one more dropout\n","          model.add(Dropout(0.5))\n","\n","          # output a softmax to squash the matrix into output probabilities\n","          model.add(Dense(4, activation='softmax'))\n","\n","          # Before the model is ready for training, it needs a few more settings.\n","            # Loss function* - measures how accurate the model is during training, we want to minimize this with the optimizer.\n","            # Optimizer - how the model is updated based on the data it sees and its loss function.\n","            # Metrics - used to monitor the training and testing steps. \"accuracy\" is the fraction of images that are correctly classified.\n","\n","          opt = tf.keras.optimizers.Adam()\n","          # opt = tf.keras.optimizers.SGD()\n","          # opt = tf.keras.optimizers.Adagrad()\n","          # opt = tf.keras.optimizers.Nadam()\n","\n","          # loss_fn = keras.losses.Huber()\n","          # loss_fn = keras.losses.MeanAbsoluteError()\n","          # loss_fn = keras.losses.LogCosh()\n","          loss_fn = 'sparse_categorical_crossentropy'\n","\n","          model.compile(optimizer=opt,\n","                        loss=loss_fn,\n","                        metrics=['accuracy'])\n","\n","          return model\n","\n","    # CNN Training Steps\n","\n","      # 1. Feed the training data to the model: In this example, our training data are the `train_images` and `train_labels` arrays, which correspond to the building images and their postdisaster labels.\n","      # 2. The model learns to associate images and labels.\n","      # 3. We ask the model to make predictions about the `test_images` array. We verify that the predictions match the labels from the `test_labels` array. By doing this, we can evaluate the accuracy of our model on predicting damage labels for post-disaster building test images.\n","\n","      # To start training,  call the `model.fit` methodâ€”the model is \"fit\" to the training data:\n","\n","    # Training of CNN Model\n","    def cnn_train(self, model, train_images, train_labels):\n","\n","          history = model.fit(train_images, train_labels, epochs=10,shuffle = True, batch_size = 5)\n","\n","    # Testing of CNN Model\n","    def cnn_test(self, model, test_images, test_labels):\n","\n","          # Evaluate Model Accuracy\n","          test_loss, test_acc = model.evaluate(test_images, test_labels)\n","\n","          print('Test accuracy:', test_acc)\n","\n","    ## SVM\n","\n","    # Perform PCA on training and testing datasets\n","    def svm_pca(self, train_images, test_images):\n","          # flatten data so its not 150x150x3\n","          train_i = []\n","\n","          for sample in train_images:\n","            train_i.append(sample.flatten())\n","\n","          test_i = []\n","\n","          for sample in test_images:\n","            test_i.append(sample.flatten())\n","\n","\n","          # pca = PCA(n_components=pca_components)  # Set the number of components you want\n","\n","          # # Fit and transform the data\n","          # train_i_pca = pca.fit_transform(train_i)\n","          # test_i_pca = pca.fit_transform(test_i)\n","\n","          # return train_i_pca, test_i_pca\n","\n","          return train_i, test_i\n","\n","    # Train and Test for SVM Classifier\n","    def svm_train_test(self, train_images, train_labels, test_images, test_labels):\n","\n","          # train the classifier\n","          poly = svm.SVC(kernel='poly', degree=3, C=1).fit(train_images, train_labels)\n","          poly_pred = poly.predict(test_images)\n","\n","          # calculate the accuracy and f1 scores for SVM with Polynomial kernel\n","          poly_accuracy = accuracy_score(test_labels, poly_pred)\n","          poly_f1 = f1_score(test_labels, poly_pred, average='weighted')\n","          print('Accuracy (Polynomial Kernel): ', \"%.2f\" % (poly_accuracy*100))\n","          print('F1 (Polynomial Kernel): ', \"%.2f\" % (poly_f1*100))\n","\n","          return poly\n","\n","    ## CNN Edge Detection\n","\n","  #for converting an image to its edges\n","    def convert_to_edge(self,building_img, t = 'Sobel'):\n","          #make the image black and white\n","          #first change to uint8 since thats whats expected here\n","          new_img = np.array(building_img, dtype=np.uint8)\n","\n","          ##TRY some filtering of some kind\n","          kernel_outline = np.array([[-1 ,-1, -1], [-1, 8, -1], [-1, -1, -1]])\n","          kernel_sharpen = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n","          new_img = cv2.filter2D(new_img, -1, kernel_sharpen)\n","          #new_img = cv2.filter2D(new_img, -1, kernel_outline)\n","\n","\n","          #make black and white\n","          new_img = cv2.cvtColor(new_img, cv2.COLOR_BGR2GRAY)\n","\n","          #new_img = cv2.GaussianBlur(new_img,(5,5),cv2.BORDER_DEFAULT)\n","\n","\n","          #do the edge detection depending on the param\n","          if t == 'Sobel':\n","            new_img = cv2.Sobel(src=new_img, ddepth=cv2.CV_64F, dx=2, dy=2, ksize=3)\n","          else:\n","            new_img = cv2.Canny(image=new_img, threshold1=100, threshold2=1000)\n","\n","          return new_img\n","\n","\n","    ## Siamese\n","    def make_siamese_pairs(self,images_train,images_test,json_images_train,json_images_test):\n","\n","          train_images = []\n","          train_labels = []\n","\n","          for i in range(len(images_train)):\n","\n","            #pre and post labels\n","            img_pre_path = images_train[i][0]\n","            img_post_path = images_train[i][1]\n","\n","            img_path = images_train[i]\n","            data = json_images_train[i]\n","\n","            #pre and post\n","            img_pre = cv2.imread(img_pre_path)\n","            img_post = cv2.imread(img_post_path)\n","\n","            for building in data['features']['xy']:\n","              damage_label = building[\"properties\"][\"subtype\"]\n","              if damage_label != \"un-classified\":\n","                cropped_img_pre = self.crop_image(building, img_pre)\n","                cropped_img_post = self.crop_image(building,img_post)\n","                #buildings_train.append(cropped_img)\n","                train_images.append([cropped_img_pre,cropped_img_post])\n","\n","\n","                if damage_label == \"no-damage\":\n","                  train_labels.append(0)\n","                if damage_label == \"minor-damage\":\n","                  train_labels.append(1)\n","                if damage_label == \"major-damage\":\n","                  train_labels.append(2)\n","                if damage_label == \"destroyed\":\n","                  train_labels.append(3)\n","\n","          #print(train_images)\n","          train_images = self.make_same_dimensions_siamese(train_images, 64) #was 150, making 300#make_same_dimensions(buildings_train, 300) #was 150, making 300\n","\n","          test_images = []\n","          test_labels = []\n","\n","          for i in range(len(images_test)):\n","\n","            #pre and post labels\n","            img_pre_path = images_train[i][0]\n","            img_post_path = images_train[i][1]\n","\n","\n","            img_path = images_test[i]\n","            data = json_images_test[i]\n","\n","            #pre and post\n","            img_pre = cv2.imread(img_pre_path)\n","            img_post = cv2.imread(img_post_path)\n","\n","            for building in data['features']['xy']:\n","              damage_label = building[\"properties\"][\"subtype\"]\n","              if damage_label != \"un-classified\":\n","                cropped_img_pre = self.crop_image(building, img_pre)\n","                cropped_img_post = self.crop_image(building,img_post)\n","                #buildings_train.append(cropped_img)\n","                test_images.append([cropped_img_pre,cropped_img_post])\n","\n","\n","                if damage_label == \"no-damage\":\n","                  test_labels.append(0)\n","                if damage_label == \"minor-damage\":\n","                  test_labels.append(1)\n","                if damage_label == \"major-damage\":\n","                  test_labels.append(2)\n","                if damage_label == \"destroyed\":\n","                  test_labels.append(3)\n","\n","          test_images = self.make_same_dimensions_siamese(test_images, 64) #make_same_dimensions(buildings_test, 300)#was 150 making 300\n","\n","          #then convert the pairs into their binary category\n","\n","          no_damage_pairs_train = []\n","          some_damage_pairs_train = []\n","\n","          no_damage_pairs_test = []\n","          some_damage_pairs_test = []\n","\n","          for i in range(len(train_labels)):\n","            if train_labels[i] == 0:\n","              no_damage_pairs_train.append(train_images[i])\n","            else:\n","              some_damage_pairs_train.append(train_images[i])\n","\n","          for i in range(len(test_labels)):\n","            if train_labels[i] == 0:\n","              no_damage_pairs_test.append(test_images[i])\n","            else:\n","              some_damage_pairs_test.append(test_images[i])\n","\n","\n","          #finally make it ready for input\n","          #seperate the pre and post and new labels\n","          #print(len(no_damage_pairs_train))\n","          #print(len(some_damage_pairs_train))\n","          #print(train_labels)\n","          #print(test_labels)\n","\n","\n","          pre = []\n","          post = []\n","          labels = []\n","          #no damage labels\n","          for i in range(len(no_damage_pairs_train)):\n","            pre.append(no_damage_pairs_train[i][0])\n","            post.append(no_damage_pairs_train[i][1])\n","            labels.append(1)\n","          #some damage labels\n","          for i in range(len(some_damage_pairs_train)):\n","            pre.append(some_damage_pairs_train[i][0])\n","            post.append(some_damage_pairs_train[i][1])\n","            labels.append(0)\n","\n","\n","          #convert to np arrays\n","          pre = np.array(pre)\n","          post = np.array(post)\n","          labels = np.array(labels)\n","\n","\n","          #get the testing data set up\n","          #seperate the pre and post and new labels\n","          pre_test = []\n","          post_test = []\n","          labels_test = []\n","          #no damage labels\n","          for i in range(len(no_damage_pairs_test)):\n","            pre_test.append(no_damage_pairs_test[i][0])\n","            post_test.append(no_damage_pairs_test[i][1])\n","            labels_test.append(1)\n","          #some damage labels\n","          for i in range(len(some_damage_pairs_test)):\n","            pre_test.append(some_damage_pairs_test[i][0])\n","            post_test.append(some_damage_pairs_test[i][1])\n","            labels_test.append(0)\n","\n","\n","          #convert to np arrays\n","          pre_test = np.array(pre_test)\n","          post_test = np.array(post_test)\n","          labels_test = np.array(labels_test)\n","\n","          return pre,post,labels,pre_test,post_test,labels_test\n","\n","    #modeling\n","    def build_siamese_model(self):\n","          #sister CNNs\n","          input_layer = Input((64, 64, 3))\n","          layer1 = Conv2D(64, (3, 3), activation='relu', padding='same')(input_layer)\n","          layer2 = MaxPooling2D((2, 2), padding='same')(layer1)\n","          layer3 = Conv2D(128, (3, 3), activation='relu', padding='same')(layer2)\n","          layer4 = MaxPooling2D((2, 2), padding='same')(layer3)\n","          layer5 = Conv2D(256, (3, 3), activation='relu', padding='same')(layer4)\n","          layer6 = MaxPooling2D((2, 2), padding='same')(layer5)\n","          layer7 = Conv2D(512, (3, 3), activation='relu', padding='same')(layer6)\n","          layer8 = MaxPooling2D((2, 2), padding='same')(layer7)\n","          layer9 = Dropout(0.25)(layer8)\n","          layer10 = Flatten()(layer9)\n","          layer11 = Dense(1024,activation = 'relu')(layer10)\n","          layer12 = Dropout(0.25)(layer11)\n","          #layer9 = GlobalAveragePooling2D()(layer8)\n","          layer13 = Dense(144)(layer12)\n","          #layer14 = Dense(64)(layer13)\n","\n","          # Create model\n","          base_model = Model(inputs=input_layer, outputs=layer13)\n","\n","          #create the siamese modeling:\n","          input_pre = Input((64,64,3))\n","          input_post = Input((64,64,3))\n","\n","          pre_model = base_model(input_pre)\n","          post_model = base_model(input_post)\n","\n","          #rather than dot layer, this source reccomends a euclidian distance layer:\n","          #https://pyimagesearch.com/2020/11/30/siamese-networks-with-keras-tensorflow-and-deep-learning/\n","\n","\n","          def euclidean_distance(vectors):\n","\n","              # unpack the vectors into separate lists\n","              (featsA, featsB) = vectors\n","              # compute the sum of squared distances between the vectors\n","              sumSquared = K.sum(K.square(featsA - featsB), axis=1, keepdims=True)\n","              # return the euclidean distance between the vectors\n","              return K.sqrt(K.maximum(sumSquared, K.epsilon()))\n","\n","          #contrastive loss layers\n","          distance = Lambda(euclidean_distance)([pre_model, post_model])\n","          output = Dense(1, activation=\"sigmoid\")(distance)\n","\n","          siamese_model = Model(inputs=[input_pre, input_post], outputs=output)\n","          return siamese_model\n","\n","    ## KNN\n","\n","    def knn_train_test(self, train_images, train_labels, test_images, test_labels):\n","\n","          # Flatten the images\n","          train_images_flat = [img.flatten() for img in train_images]\n","          test_images_flat = [img.flatten() for img in test_images]\n","\n","          # Define a range of neighbors\n","          neighbors = range(1, 11)\n","\n","          accuracies = []\n","          f1_scores = []\n","\n","          for k in neighbors:\n","              # Initialize the K-NN classifier\n","              knn_classifier = KNeighborsClassifier(n_neighbors=k)\n","\n","              # Train the classifier\n","              knn_classifier.fit(train_images_flat, train_labels)\n","\n","              # Predict the labels for the test images\n","              predicted_labels = knn_classifier.predict(test_images_flat)\n","\n","              # Calculate accuracy\n","              accuracy = accuracy_score(test_labels, predicted_labels)\n","              accuracies.append(accuracy)\n","\n","              # Calculate F1 score\n","              f1 = f1_score(test_labels, predicted_labels, average='weighted')\n","              f1_scores.append(f1)\n","\n","          # Plotting\n","          plt.plot(neighbors, accuracies, marker='o', label='Accuracy')\n","          plt.plot(neighbors, f1_scores, marker='+', label='F1 Score')\n","          plt.title('Accuracy and F1 Score vs. Number of Neighbors')\n","          plt.xlabel('Number of Neighbors')\n","          plt.ylabel('Score')\n","          plt.legend()\n","          plt.xticks(neighbors)\n","\n","          # Create DataFrame\n","          df = pd.DataFrame({'Accuracies': accuracies, 'F1 Scores': f1_scores, '# of neighbors': neighbors})\n","\n","          # Print DataFrame\n","          print(df)\n","\n","    ### Postprocessing: Classification Results Analysis\n","\n","    ## CNN\n","\n","    # get confustion matrix for CNN\n","    def get_matrix_cnn(self, model, images_train, json_images_train, index):\n","\n","          test_predictions = []\n","\n","          # for img in test_images:\n","          #   p = model.predict(img)\n","          #   test_predictions.append(p)\n","\n","          img_path = images_train[index]\n","          data = json_images_train[index]\n","\n","          img = cv2.imread(img_path)\n","\n","          test_data_demo = []\n","\n","          for building in data['features']['xy']:\n","              damage_label = building[\"properties\"][\"subtype\"]\n","              if damage_label != \"un-classified\":\n","                  cropped_img = self.crop_image(building, img)\n","                  if damage_label == \"no-damage\":\n","                      test_data_demo.append((cropped_img, 0))\n","                  elif damage_label == \"minor-damage\":\n","                      test_data_demo.append((cropped_img, 1))\n","                  elif damage_label == \"major-damage\":\n","                      test_data_demo.append((cropped_img, 2))\n","                  elif damage_label == \"destroyed\":\n","                      test_data_demo.append((cropped_img, 3))\n","\n","          test_images_demo, test_labels_demo = zip(*test_data_demo)\n","\n","          # Resize images to the same dimensions\n","          test_images_demo = self.make_same_dimensions(test_images_demo, 150)\n","\n","          test_images_demo = np.array(test_images_demo)\n","          test_labels_demo = np.array(test_labels_demo)\n","\n","          test_predictions = model.predict(test_images_demo)\n","\n","          preds = []\n","          for probabilities in test_predictions:\n","            maximum = max(probabilities[0], probabilities[1], probabilities[2], probabilities[3])\n","            if maximum == probabilities[0]:\n","              preds.append(0)\n","            elif maximum == probabilities[1]:\n","              preds.append(1)\n","            elif maximum == probabilities[2]:\n","              preds.append(2)\n","            else:\n","              preds.append(3)\n","\n","          # actual values are the rows\n","          # predicted values are the cols\n","          #we had this backwards, but i confirmed with counts of truth labels\n","          matrix = tf.math.confusion_matrix(test_labels_demo, preds)\n","\n","          return matrix, preds\n","\n","    ## SVM\n","\n","    # Get confusion matrix for SVM\n","    def get_matrix_svm(self, poly, images_train, json_images_train, index):\n","\n","          test_predictions = []\n","\n","          img_path = images_train[index]\n","          data = json_images_train[index]\n","\n","          img = cv2.imread(img_path)\n","\n","          test_data_demo = []\n","\n","          for building in data['features']['xy']:\n","              damage_label = building[\"properties\"][\"subtype\"]\n","              if damage_label != \"un-classified\":\n","                  cropped_img = self.crop_image(building, img)\n","                  if damage_label == \"no-damage\":\n","                      test_data_demo.append((cropped_img, 0))\n","                  elif damage_label == \"minor-damage\":\n","                      test_data_demo.append((cropped_img, 1))\n","                  elif damage_label == \"major-damage\":\n","                      test_data_demo.append((cropped_img, 2))\n","                  elif damage_label == \"destroyed\":\n","                      test_data_demo.append((cropped_img, 3))\n","\n","          test_images_demo, test_labels_demo = zip(*test_data_demo)\n","\n","          # Resize images to the same dimensions\n","          test_images_demo = self.make_same_dimensions(test_images_demo, 150)\n","\n","          test_images_demo = np.array(test_images_demo)\n","          test_labels_demo = np.array(test_labels_demo)\n","\n","          # print(\"test_images_demo size: \" + str(test_images_demo.shape) + \"\\n\")\n","\n","          test_i = []\n","\n","          for sample in test_images_demo:\n","            test_i.append(sample.flatten())\n","\n","          # print(\"test_i size: \" + str(len(test_i)) + \"\\n\")\n","\n","          # pca = PCA(n_components=pca_components)  # Set the number of components you want\n","\n","          # # Fit and transform the data\n","          # test_i_pca = pca.fit_transform(test_i)\n","\n","          # poly_pred = poly.predict(test_i_pca)\n","\n","          poly_pred = poly.predict(test_i)\n","\n","          matrix_poly = tf.math.confusion_matrix(test_labels_demo, poly_pred)\n","\n","          return matrix_poly, poly_pred\n","\n","\n","    ## CNN Edge Detection\n","\n","    ## Siamese\n","\n","    ## KNN\n","\n","    def get_matrix_knn(self, train_images, train_labels, test_images, test_labels):\n","\n","          # Flatten the images\n","          train_images_flat = [img.flatten() for img in train_images]\n","          test_images_flat = [img.flatten() for img in test_images]\n","\n","          # Specify number of neighbors k\n","          while True:\n","            try:\n","                # Specify number of neighbors k\n","                k = int(input(\"Enter the number of neighbors (between 1 and 10) for a Confusion Matrix of predictions: \"))\n","                if k < 1 or k > 10:\n","                    raise ValueError(\"Please enter a number between 1 and 10.\")\n","                else:\n","                    break\n","            except ValueError as e:\n","                print(e)\n","\n","          # Initialize the K-NN classifier\n","          knn_classifier = KNeighborsClassifier(k)\n","\n","          # Train the classifier\n","          knn_classifier.fit(train_images_flat, train_labels)\n","\n","          # Predict the labels for the test images\n","          test_predictions = knn_classifier.predict(test_images_flat)\n","\n","          # actual values are the rows\n","          # predicted values are the columns\n","          matrix = tf.math.confusion_matrix(test_labels, test_predictions)\n","\n","          return matrix, test_predictions\n","\n","    ##Code to generate a nice looking confusion matrix by color\n","    #utalizes the matplotlib pcolormesh, I followed documentation on matplotlib.org for various sections of this code\n","    #links:\n","    #https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.pcolormesh.html\n","    #https://matplotlib.org/stable/gallery/images_contours_and_fields/image_annotated_heatmap.html#sphx-glr-gallery-images-contours-and-fields-image-annotated-heatmap-py\n","    #https://matplotlib.org/stable/gallery/text_labels_and_annotations/placing_text_boxes.html\n","\n","    def visualize_confusion_matrix(self, matrix, train_images, test_images):\n","          #build the data array, flipping the order of the rows\n","          #this is nessassary since the pcolormesh has 0 at the bottom rather than top like a typical\n","          #confusion matrix\n","          data = []\n","          for row in range(0,4):\n","            currCol = []\n","            for col in range(0,4):\n","              currCol.append(matrix[row][col].numpy())\n","            data.insert(0,currCol)\n","\n","          print(data[0])\n","          #use the pcolormesh function, following the documentations\n","          Z = data\n","          x = np.arange(0,4,1)\n","          y = np.arange(0,4,1)\n","\n","          maxVal = max(max(data[0]),max(data[1]),max(data[2]),max(data[3]))\n","\n","          fig, ax = plt.subplots()\n","          ax.pcolormesh(x, y, Z, cmap = 'viridis')\n","\n","          #calculate percentages of the columns for annotation\n","          percentages = []\n","          for col in range(0,4):\n","            currCol = []\n","            sum = 0\n","            #gets the total guesses\n","            for i in range(0,4):\n","              sum = sum + data[i][col]\n","            #calculates percentages\n","            for i in range(0,4):\n","              if sum != 0:\n","                currCol.append((data[i][col]/sum) * 100)\n","              else:\n","                currCol.append(0.00)\n","            percentages.append(currCol)\n","\n","          #adding text annotations in boxes\n","          for i in range(0,4):\n","            for j in range(0,4):\n","              #change the text color if nessassary, 75% of max make the text black\n","              if data[i][j] < maxVal*0.75:\n","                text = ax.text(j, i, str(data[i][j]) + \"\\n\" +str(round(percentages[j][i],2)) + \"%\" , ha=\"center\", va=\"center\", color=\"w\")\n","              else:\n","                text = ax.text(j, i, str(data[i][j]) + \"\\n\" +str(round(percentages[j][i],2)) + \"%\" , ha=\"center\", va=\"center\", color=\"k\")\n","\n","          #add additional text to bottom corner\n","          ax.text(-1.5,-1.05, \"Perfect Classifier = Only Diagonal Filled\")\n","          ax.text(-1.5,-1.25, \"% = Correctness given guess type\")\n","          ax.text(-1.5,-1.45, \"# of Train Buildings: \" + str(train_images.shape[0]))\n","          ax.text(-1.5,-1.65, \"# of Test Buildings: \" + str(test_images.shape[0]))\n","\n","\n","          #axes info\n","          classLabelsX = [\"No Damage\", 'Minor Damage', 'Major Damage', 'Destroyed']\n","          classLabelsY = ['Destroyed','Major Damage','Minor Damage','No Damage']\n","          ax.set_xticks(np.arange(4), labels=classLabelsX)\n","          ax.set_yticks(np.arange(4), labels=classLabelsY)\n","\n","          #plots the confusion matrix with titles\n","          plt.title(\"Confusion Matrix\")\n","          plt.xlabel(\"Predicted Values\")\n","          plt.ylabel(\"Ground Truth\")\n","          plt.show()\n","\n","\n","    def visualize_confusion_matrix_siamese(self,matrix):\n","      #build the data array, flipping the order of the rows\n","      #this is nessassary since the pcolormesh has 0 at the bottom rather than top like a typical\n","      #confusion matrix\n","      data = []\n","      for row in range(0,2):\n","        currCol = []\n","        for col in range(0,2):\n","          currCol.append(matrix[row][col].numpy())\n","        data.insert(0,currCol)\n","\n","      print(data[0])\n","      #use the pcolormesh function, following the documentations\n","      Z = data\n","      x = np.arange(0,2,1)\n","      y = np.arange(0,2,1)\n","\n","      maxVal = max(max(data[0]),max(data[1]))\n","\n","      fig, ax = plt.subplots()\n","      ax.pcolormesh(x, y, Z, cmap = 'viridis')\n","\n","      #calculate percentages of the columns for annotation\n","      percentages = []\n","      for col in range(0,2):\n","        currCol = []\n","        sum = 0\n","        #gets the total guesses\n","        for i in range(0,2):\n","          sum = sum + data[i][col]\n","        #calculates percentages\n","        for i in range(0,2):\n","          if sum != 0:\n","            currCol.append((data[i][col]/sum) * 100)\n","          else:\n","            currCol.append(0.00)\n","        percentages.append(currCol)\n","\n","      #adding text annotations in boxes\n","      for i in range(0,2):\n","        for j in range(0,2):\n","          #change the text color if nessassary, 75% of max make the text black\n","          if data[i][j] < maxVal*0.75:\n","            text = ax.text(j, i, str(data[i][j]) + \"\\n\" +str(round(percentages[j][i],2)) + \"%\" , ha=\"center\", va=\"center\", color=\"w\")\n","          else:\n","            text = ax.text(j, i, str(data[i][j]) + \"\\n\" +str(round(percentages[j][i],2)) + \"%\" , ha=\"center\", va=\"center\", color=\"k\")\n","\n","      #add additional text to bottom corner\n","      ax.text(-1.5,-1.05, \"Perfect Classifier = Only Diagonal Filled\")\n","      ax.text(-1.5,-1.25, \"% = Correctness given guess type\")\n","      #ax.text(-1.5,-1.45, \"# of Train Buildings: \" + str(train_images.shape[0]))\n","      #ax.text(-1.5,-1.65, \"# of Test Buildings: \" + str(test_images.shape[0]))\n","\n","\n","      #axes info\n","      classLabelsX = [\"Damage\",\"No Damage\"]\n","      classLabelsY = [\"No Damage\", \"Damage\"]\n","      ax.set_xticks(np.arange(2), labels=classLabelsX)\n","      ax.set_yticks(np.arange(2), labels=classLabelsY)\n","\n","      #plots the confusion matrix with titles\n","      plt.title(\"Confusion Matrix\")\n","      plt.xlabel(\"Predicted Values\")\n","      plt.ylabel(\"Ground Truth\")\n","      plt.show()\n","\n","\n","    def visualize_confusion_matrix_svm(self, matrix, train_images, test_images):\n","          #build the data array, flipping the order of the rows\n","          #this is nessassary since the pcolormesh has 0 at the bottom rather than top like a typical\n","          #confusion matrix\n","          data = []\n","          for row in range(0,4):\n","            currCol = []\n","            for col in range(0,4):\n","              currCol.append(matrix[row][col].numpy())\n","            data.insert(0,currCol)\n","\n","          print(data[0])\n","          #use the pcolormesh function, following the documentations\n","          Z = data\n","          x = np.arange(0,4,1)\n","          y = np.arange(0,4,1)\n","\n","          maxVal = max(max(data[0]),max(data[1]),max(data[2]),max(data[3]))\n","\n","          fig, ax = plt.subplots()\n","          ax.pcolormesh(x, y, Z, cmap = 'viridis')\n","\n","          #calculate percentages of the columns for annotation\n","          percentages = []\n","          for col in range(0,4):\n","            currCol = []\n","            sum = 0\n","            #gets the total guesses\n","            for i in range(0,4):\n","              sum = sum + data[i][col]\n","            #calculates percentages\n","            for i in range(0,4):\n","              if sum != 0:\n","                currCol.append((data[i][col]/sum) * 100)\n","              else:\n","                currCol.append(0.00)\n","            percentages.append(currCol)\n","\n","          #adding text annotations in boxes\n","          for i in range(0,4):\n","            for j in range(0,4):\n","              #change the text color if nessassary, 75% of max make the text black\n","              if data[i][j] < maxVal*0.75:\n","                text = ax.text(j, i, str(data[i][j]) + \"\\n\" +str(round(percentages[j][i],2)) + \"%\" , ha=\"center\", va=\"center\", color=\"w\")\n","              else:\n","                text = ax.text(j, i, str(data[i][j]) + \"\\n\" +str(round(percentages[j][i],2)) + \"%\" , ha=\"center\", va=\"center\", color=\"k\")\n","\n","          #add additional text to bottom corner\n","          ax.text(-1.5,-1.05, \"Perfect Classifier = Only Diagonal Filled\")\n","          ax.text(-1.5,-1.25, \"% = Correctness given guess type\")\n","          ax.text(-1.5,-1.45, \"# of Train Buildings: \" + str(len(train_images)))\n","          ax.text(-1.5,-1.65, \"# of Test Buildings: \" + str(len(test_images)))\n","\n","\n","          #axes info\n","          classLabelsX = [\"No Damage\", 'Minor Damage', 'Major Damage', 'Destroyed']\n","          classLabelsY = ['Destroyed','Major Damage','Minor Damage','No Damage']\n","          ax.set_xticks(np.arange(4), labels=classLabelsX)\n","          ax.set_yticks(np.arange(4), labels=classLabelsY)\n","\n","          #plots the confusion matrix with titles\n","          plt.title(\"Confusion Matrix\")\n","          plt.xlabel(\"Predicted Values\")\n","          plt.ylabel(\"Ground Truth\")\n","          plt.show()\n","\n","    #Used as a reference for function idea: https://www.kaggle.com/code/lezwon/xview2-challenge#kln-47, but chose a different but similar method\n","    #referene for cv2.fillpoly: https://www.geeksforgeeks.org/draw-a-filled-polygon-using-the-opencv-function-fillpoly/\n","\n","    # Function to draw predicted labels onto image\n","    def draw_new_labels(self, img, data, preds):\n","          index = 0\n","          for building in data['features']['xy']:\n","\n","            #split the string\n","            spaces = building['wkt'].split(' ')\n","\n","            #remove the first element 'POLYGON'\n","            spaces.pop(0)\n","            #remove the parenthesis from the first element\n","            spaces[0] = spaces[0][2::]\n","            #remove the parethesis of the last element\n","            spaces[len(spaces)-1] = spaces[len(spaces)-1][:-2]\n","\n","            #get rid of the commas in the second point\n","            for i in range(len(spaces)):\n","              spaces[i] = spaces[i].replace(\",\",\"\")\n","\n","            #make them integers and tuples for points\n","            points = []\n","            for i in range(0,len(spaces),2):\n","              points.append((int(float(spaces[i])), int(float(spaces[i+1]))))\n","\n","            points = np.array(points)\n","\n","            #grab the damage label\n","            # damage_label = building[\"properties\"][\"subtype\"]\n","\n","            damage_label = preds[index]\n","\n","            #CV2 uses BGR not RGB\n","            #default to cyan\n","            COLOR = (255,255,25)\n","            if damage_label == 0:\n","              #no-damage is white\n","              COLOR = (255,255,255)\n","            if damage_label == 1:\n","              #minor damage is green\n","              COLOR = (128,255,102)\n","            if damage_label == 2:\n","              #major is orange\n","              COLOR = (0,153,250)\n","            if damage_label == 3:\n","              #red for destoyed\n","              COLOR = (0,0,255)\n","\n","            #draw the proper polygon\n","            cv2.fillPoly(img, [points],COLOR)\n","\n","            index += 1\n","\n","          return img\n","\n","    # Show post-disaster image with true labels and with predicted labels\n","    def show_post_true_predicted(self, images_train, index, preds):\n","          sample_img = images_train[index]\n","          img_post = cv2.imread(sample_img)\n","\n","          # get the json data\n","          label_path = sample_img.replace('png', 'json').replace('images', 'labels')\n","          # takes a while for below code to run so once it runs, work with data variable in new cell\n","          with open(label_path, \"rb\") as file:\n","              data = json.load(file)\n","\n","          img = self.draw_labels(img_post, data)\n","          self.show_with_size(img,5,8, 'Post-Disaster Image with True Labels')\n","\n","          img = self.draw_new_labels(img_post, data, preds)\n","          self.show_with_size(img,5,8, 'Post-Disaster Image with Predicted Labels')\n","\n","\n","    # main function coordinates user interface in demo\n","    def main(self):\n","\n","        # Get user name for path identification\n","        self.get_user_name()\n","\n","        # Get disaster type\n","        disaster = self.choose_disaster()\n","\n","        # Gather images from disaster\n","        images_train, json_images_train = self.gather_images_json(disaster)\n","\n","        # choosing which image in images_train to make the sample image\n","        index = 2\n","\n","        # Print pre- and post-disaster images for a sample image from this disaster\n","        self.show_pre_post(images_train, index)\n","\n","        # Print post-disaster sample image with its true labels\n","        self.show_post_labels(images_train, index)\n","\n","        # Train disaster and test on validation dataset of images\n","        train_images, train_labels, test_images, test_labels = self.get_train_test_split(images_train, json_images_train)\n","\n","        print(\"\\nTrain Set Stats\")\n","        self.print_class_stats(train_labels)\n","        print(\"\\nTest Set Stats\")\n","        self.print_class_stats(test_labels)\n","\n","        print(\"\\n\\n\")\n","\n","        # Choose model and build it accordingly\n","        model_type = self.choose_model()\n","\n","        # CNN Model\n","        if model_type == 1:\n","            model = self.build_CNN()\n","\n","            print(\"Training the CNN\")\n","            self.cnn_train(model, train_images, train_labels)\n","            print(\"\\nTesting the CNN\")\n","            self.cnn_test(model, test_images, test_labels)\n","\n","            matrix, preds = self.get_matrix_cnn(model, images_train, json_images_train, index)\n","\n","        # CNN Edge Detection\n","        elif model_type == 2:\n","\n","          #processing the images into edges\n","          #iterate though the test and the train set doing the edge detection\n","          edge_train = []\n","          edge_test = []\n","          DETECTION_TYPE = \"Canny\"\n","          for i in range(0,len(train_images)):\n","            img_post = self.convert_to_edge(train_images[i], t = DETECTION_TYPE)\n","            edge_train.append(img_post)\n","          for i in range(0,len(test_images)):\n","            img_post = self.convert_to_edge(test_images[i], t = DETECTION_TYPE)\n","            edge_test.append(img_post)\n","\n","          #use the same CNN as above\n","          model = self.build_CNN()\n","\n","          print(\"Training the CNN-Edge Detection\")\n","          self.cnn_train(model, train_images, train_labels)\n","          print(\"\\nTesting the CNN- Edge Detection\")\n","          self.cnn_test(model, test_images, test_labels)\n","\n","          matrix, preds = self.get_matrix_cnn(model, images_train, json_images_train, index)\n","\n","\n","        # Siamese Model\n","        elif model_type == 3:\n","\n","          #for siamese we need the pre and the post images, so re-gather the pre images\n","          train_images,test_images,json_images_train,json_images_test = self.gather_images_siamese_json(disaster)\n","\n","          #print(train_images)\n","          #print(json_images_train)\n","\n","          #build the pairs\n","          pre,post,labels,pre_test,post_test,labels_test = self.make_siamese_pairs(train_images,test_images,json_images_train,json_images_test)\n","\n","          #build the model\n","          model = self.build_siamese_model()\n","          #compile the model\n","          model.compile(optimizer='adam', loss= 'binary_crossentropy',metrics = ['accuracy'])\n","          #train the model\n","\n","          classWeight = compute_class_weight('balanced', classes = np.unique(labels), y = labels)\n","          classWeight = dict(enumerate(classWeight))\n","\n","          #model train\n","          model.fit([pre, post], labels, epochs=10,batch_size = 16,shuffle=True, verbose=True, class_weight = classWeight)\n","\n","          #predictions\n","          model_predictions = model.predict([pre_test,post_test])\n","\n","          #generate the predictions\n","          preds = []\n","          for i in range(len(model_predictions)):\n","            #maximum = max(model_predictions[i][0],model_predictions[i][1])\n","            #if maximum == model_predictions[i][0]:\n","            if model_predictions[i] < 0.5:\n","              preds.append(0)\n","            else:\n","              preds.append(1)\n","          #getting the confusion matrix\n","          matrix = tf.math.confusion_matrix(labels_test,preds)\n","\n","        # SVM Model\n","        elif model_type == 4:\n","            train_images, test_images = self.svm_pca(train_images, test_images)\n","\n","            model = self.svm_train_test(train_images, train_labels, test_images, test_labels)\n","\n","            matrix, preds = self.get_matrix_svm(model, images_train, json_images_train, index)\n","\n","            print(matrix)\n","\n","        # KNN Model\n","        elif model_type == 5:\n","            self.knn_train_test(train_images, train_labels, test_images, test_labels)\n","            matrix, preds = self.get_matrix_knn(train_images, train_labels, test_images, test_labels)\n","\n","        print(\"\\n\\nConfusion Matrix for Model Against Sample Image\")\n","\n","        # Post processing to output confusion matrix and postdisaster ground truth and prediction labels\n","        if model_type != 3 and model_type != 4:\n","          self.visualize_confusion_matrix(matrix, train_images, test_images)\n","        elif model_type == 4:\n","          self.visualize_confusion_matrix_svm(matrix, train_images, test_images)\n","        else:\n","          self.visualize_confusion_matrix_siamese(matrix)\n","\n","\n","        self.show_post_true_predicted(images_train, index, preds)\n","\n","if __name__ == \"__main__\":\n","    demo = Demo()\n","    demo.main()\n"]}],"metadata":{"colab":{"provenance":[{"file_id":"15yiuhx51S154FSleWmFoe4BPa3AHrjJe","timestamp":1716057630928}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}